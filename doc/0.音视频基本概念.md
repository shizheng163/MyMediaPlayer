# 音视频基本概念
    作者:史正
    邮箱:shizheng163@126.com
    如有错误还请及时指正
    如果有错误的描述给您带来不便还请见谅
    如需交流请发送邮件,欢迎联系
-   我的csdn    : **[https://blog.csdn.net/shizheng163](https://blog.csdn.net/shizheng163)**<br>
-   我的github  : **[https://github.com/shizheng163](https://github.com/shizheng163)**

**目录**
- [音视频基本概念](#%E9%9F%B3%E8%A7%86%E9%A2%91%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5)
- [简述](#%E7%AE%80%E8%BF%B0)
- [复用与解复用](#%E5%A4%8D%E7%94%A8%E4%B8%8E%E8%A7%A3%E5%A4%8D%E7%94%A8)
- [解码与编码](#%E8%A7%A3%E7%A0%81%E4%B8%8E%E7%BC%96%E7%A0%81)
- [图像采集与图像编码](#%E5%9B%BE%E5%83%8F%E9%87%87%E9%9B%86%E4%B8%8E%E5%9B%BE%E5%83%8F%E7%BC%96%E7%A0%81)
- [图像大小计算](#%E5%9B%BE%E5%83%8F%E5%A4%A7%E5%B0%8F%E8%AE%A1%E7%AE%97)
- [音频](#%E9%9F%B3%E9%A2%91)
- [参考文章](#%E5%8F%82%E8%80%83%E6%96%87%E7%AB%A0)
***

# 简述
我们日常生活中经常会接触到一些音视频文件，例如mp4, avi, rmvb, mkv等等。
这些文件格式其实是把视频数据与音频数据打包后的文件格式，有些音视频文件中可能还会封装一些字幕数据。
那么播放器是如何将一个视频文件进行播放展示给我们呢？

先放上雷神的一张图，描述下音视频播放的流程, 我们将以这张图中视频分支为例进行讲解。
![音视频播放流程图](./音视频播放流程图.jpg)
图片来自雷神博客:[https://blog.csdn.net/leixiaohua1020/article/details/18893769](https://blog.csdn.net/leixiaohua1020/article/details/18893769)

# 复用与解复用
上文已经简单描述过，MP4等格式的文件类型是把音视频数据糅合在一起存放的文件类型。
当播放器播放数据时，首先会把这些文件拆分为纯粹的 `音频数据（压缩)` 与 `视频数据（压缩）`。
这些音视频数据也是可以通过播放器单独播放的，只不过播放时是没有视频或者音频的。

将MP4等格式的文件拆分为视频或音频等比较单一的数据的行为我们称之为 `解复用（解封装）` ，也就是音视频领域所说的Demux.
与之对应的，将单一的数据视频，与音频数据组合起来，打包成MP4等格式的操作我们称之为`复用（封装）`Mux.

我们知道，当连续的图片播放的比较快的时候，里面的人物与风景就会动起来，如同动画一样呈现在我们面前，当图像播放的速度比较快时，肉眼就难以辨别图片间的变化，这时看这些连续的图片其实也就相当于看一段完整的视频了。所以，这里我们可以认为 ***视频是图片的集合***。

要想图片播放起来达到视频的效果，大概需要25张图片/s的效果，所以一般电影的帧率（一秒钟显示图片的数目）都是在25帧左右。小于20帧的视频或者摄像头比较少见。

我们平时所见的超清/全高清（1920x1080）电影大概有好几GB，如果一张图片有80KB,那么一小时的视频就需要60x60x25x80=6.86G左右，两小时的视频 = 13G左右，这显然与我们平时见到的视频大小是不匹配的，也是现如今的存储技术无法所接受的。所有上述解封装后的视频都是 ***压缩后的图像的集合***

显然，我们拿到压缩后图像是无法进行播放的，这时我们需要将压缩数据分解为一张张图片，然后再显示出来。

-   将压缩后的视频数据分解为图片的操作就是 `解码`

# 解码与编码

上一节已经提过，解封装之后的视频都是经过压缩的图像集合，我们将图像集合进行压缩的过程称之为 `编码`， 同样的，将压缩后的图像集合分解为一张张图片的过程称为 `解码`

现在常用的编解码算法有h264、h265(hevc)、mpeg4等，也就是压缩后的视频格式。
音频常见的有aac,pcm等编解码算法。
这里可以看下雷神的博客，描写的比较详细：
> [https://blog.csdn.net/leixiaohua1020/article/details/18893769](https://blog.csdn.net/leixiaohua1020/article/details/18893769)

将压缩后的数据解码为图片之后就可以将这些图像连续的显示在画面上进行播放了，将图片显示在画面上的过程称为`渲染`

我们将解码后的图片称为`帧`Frame, 每秒显示的帧数称为`帧率`

那么，解码后的图像与我们平时见到的图像（Jpeg、Png、BMP）一样吗？答案是否定的。
解码后的图像的数据格式称为`I420`（标准的YUV420存储）, 这种图像一般的图像显示器都不支持直接显示。

到这一步来说，作为播放器开发就足够了，至于底层库如何将这种`I420`数据渲染到画面上就不是我们需要关心的了（我也不知道）。感兴趣的小伙伴可以自行研究。

这里继续介绍一下解码后的`I420`图像与我们平时所见到的图像的区别。

# 图像采集与图像编码
一般来说，我们通过相机或者摄像头采集到的数据为`RGB24`，我们平时见到的图像（ PNG, ICO, BMP, JPEG）都是把采集到的数据编码之后得来的，也就是说将采集到的数据经过一系列的计算然后加上对应图像的格式头形成的格式。

那么如此来回编码的意义何在呢？ 降低存储!

`I420`就是将`RGB24`进行编码之后的一种数据格式，它是h264编码标准规定的输入类型，大小为`RGB24`的二分之一。

而`BMP`的大小基本与采集出来的`RGB24`的大小相同。

至于`JPEG`的大小就与压缩质量系数有关了，一般为原始图像大小的几十分之一。

如果你看到了现在，应该就可以了解制作视频的步骤了:

    `采集`RGB24->`图像编码`为I420->`视频编码`为H264->与音频或其他数据`封装`为MP4等其他格式。

对应的，视频播放的步骤:

    MP4解封装->h264视频解码->I420图像解码->RGB24渲染

对于几种图像格式之间的区别，感兴趣的可以自行了解。

# 图像大小计算

那么一张图像的大小怎么计算的呢？
-   图像占用内存空间的大小 = 分辨率 * 位深度 ／ 8
-   分辨率:宽x高，例如1920x1080
-   位深度：一个像素点所占空间大小，单位为bit。每个像素可以使用的颜色信息数量,每个像素使用的信息位数越多，可用的颜色就越多，颜色表现就更逼真。例如，位深度为8(一比特)的可用颜色数据为2^8=256，也就是我们平时说的256色。

例如：
一幅图像分辨率：1024*768,24位，则其大小计算如下：
    所占空间大小 = 1024 * 768 * 24 / 8 = 2359296 byte = 2304 KB

当然，以上公式只能用来计算BMP位图等没有经过压缩后的图像，像JPEG这种图像格式是经过压缩编码后的，它一般是24位几千万色。

另外，`RGB24`的大小也可通过此方法计算，它是R、G、B各占8bit，24位

# 音频
对于音频，目前了解不多，只知道是数字信号的集合，以后了解加深之后会在这里补充的。

# 参考文章
- [雷霄骅-视音频编解码技术零基础学习方法](https://blog.csdn.net/leixiaohua1020/article/details/18893769)
- [图像大小计算](https://zhidao.baidu.com/question/102654053.html)
- [bmp和yuv格式](https://blog.csdn.net/mlfcjob/article/details/78889317)
- [像素,DPI,图像分辨率](https://baijiahao.baidu.com/s?id=1566896184355152&wfr=spider&for=pc)
- [解码后的数据格式](https://www.cnblogs.com/lihaiping/p/ffmpeg.html)
- [RGB与YUV之前的转换](https://blog.csdn.net/wo6694458/article/details/61640647)
- [YUV420存储为BMP和JPG图片](https://blog.csdn.net/yixianfeng41/article/details/52181578)  

另外推荐几个音视频学习网站:

-  [雷神博客](https://blog.csdn.net/leixiaohua1020/)
-  [云天之巅](http://blog.yundiantech.com/?log=index)